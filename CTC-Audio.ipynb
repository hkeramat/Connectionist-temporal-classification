{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a262640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe78905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Zipe file TIMIT data attached \n",
    "zip_path = 'timit.zip'\n",
    "extract_to_path = os.path.dirname(zip_path)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path=extract_to_path)\n",
    "\n",
    "print(\"Files extracted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e89886",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./timit/timit/allsenlist.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Splitting the lines\n",
    "data = [line.strip().split('\\t') for line in lines]\n",
    "\n",
    "# Creating a DataFrame( audio, text)\n",
    "df = pd.DataFrame(data, columns=['filename', 'dummy', 'text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df.iterrows(): # Na handling \n",
    "    if(row[2]==None):\n",
    "        row[2] = row[1]\n",
    "del df['dummy']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = [ ]\n",
    "for i in range(0,160):\n",
    "    s = df.iloc[i,0]\n",
    "    if(s[4]=='m'):\n",
    "        gender.append('male')\n",
    "    else:\n",
    "        gender.append('female')\n",
    "gender = pd.Series(gender)\n",
    "df['gender'] = gender\n",
    "df.head(160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16afd769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,160):\n",
    "    df.iloc[i,0]= './timit/timit/' + df.iloc[i,0] + '.wav'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8097f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "def preprocess_labels(text):\n",
    "    # Labels from 0 to num_classes-1 : 'a' maps to 0, 'b' to 1, ..., 'z' to 25, and space to 26\n",
    "    label = [ord(char) - ord('a') if 'a' <= char <= 'z' else 26 for char in text.lower() if char == ' ' or 'a' <= char <= 'z']\n",
    "    return label\n",
    "\n",
    "\n",
    "# Updating the data to (spectrograms, labels)\n",
    "def preprocess_data(df, max_sequence_length):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        file_path = df.iloc[i, 0]\n",
    "        text = df.iloc[i, 1]\n",
    "        audio, _ = librosa.load(file_path, sr=16000)\n",
    "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=16000, n_mels=128)\n",
    "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        if spectrogram.shape[1] < max_sequence_length:\n",
    "            pad_width = max_sequence_length - spectrogram.shape[1]\n",
    "            spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spectrogram = spectrogram[:, :max_sequence_length]\n",
    "        spectrograms.append(spectrogram)\n",
    "        processed_label = preprocess_labels(text)\n",
    "        labels.append(processed_label)\n",
    "    return spectrograms, labels\n",
    "\n",
    "\n",
    "# CTC model with BLSTM\n",
    "class CTCModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CTCModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 64, kernel_size=(3, 3), padding=(1, 1)) # Had to add conv to make the matrix right\n",
    "        self.lstm = nn.LSTM(64 * input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.permute(0, 3, 1, 2)  \n",
    "        x = x.reshape(x.size(0), x.size(1), -1)  \n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    max_sequence_length = 500\n",
    "    spectrograms, labels = preprocess_data(df, max_sequence_length)\n",
    "\n",
    "    # Converting to PyTorch tensors\n",
    "    sequences_tensor = torch.tensor(spectrograms, dtype=torch.float32).unsqueeze(1)\n",
    "    labels_tensor = torch.nn.utils.rnn.pad_sequence([torch.tensor(label, dtype=torch.long) for label in labels], batch_first=True)\n",
    "    label_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(sequences_tensor, labels_tensor, label_lengths)\n",
    "    batch_size = 32\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    # Instantiating the model\n",
    "    input_size = 128  # # of MEL frequency bins\n",
    "    hidden_size = 256\n",
    "    num_layers = 3\n",
    "    num_classes = 26  # # of characters (a-z)\n",
    "    model = CTCModel(input_size, hidden_size, num_layers, num_classes + 1)  # +1 for blank label\n",
    "\n",
    "    criterion = nn.CTCLoss(blank=num_classes, reduction='mean', zero_infinity=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training ...\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for sequences, labels, label_lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(sequences)\n",
    "        input_lengths = torch.full((sequences.size(0),), logits.size(1), dtype=torch.long)\n",
    "        logits = logits.log_softmax(2).permute(1, 0, 2)\n",
    "        \n",
    "        ctc_loss = criterion(logits, labels, input_lengths, label_lengths)\n",
    "        \n",
    "        ctc_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += ctc_loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    average_loss = total_loss / num_batches\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d716e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "\n",
    "# Mapping from numerical labels to characters\n",
    "label_to_char = {i: chr(ord('a') + i) for i in range(num_classes)}\n",
    "label_to_char[num_classes] = ' ' \n",
    "label_to_char[num_classes + 1] = '' \n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, labels, label_lengths in dataloader:\n",
    "        logits = model(sequences)\n",
    "        input_lengths = torch.full((sequences.size(0),), logits.size(1), dtype=torch.long)\n",
    "        logits = logits.log_softmax(2).permute(1, 0, 2)\n",
    "        \n",
    "        # ctc_greedy_decoder\n",
    "        decoded_preds = []\n",
    "        for logit, length in zip(logits.permute(1, 0, 2), input_lengths):\n",
    "            logit = logit[:length]\n",
    "            decoded = torch.argmax(logit, dim=-1)\n",
    "            decoded_preds.append(decoded.tolist())\n",
    "        \n",
    "        # Predictions and ground truth \n",
    "        for pred, label, length in zip(decoded_preds, labels, label_lengths):\n",
    "            pred_chars = ''.join([label_to_char[p] for p in pred if p != num_classes + 1])\n",
    "            label_chars = ''.join([label_to_char[l.item()] for l in label[:length]])\n",
    "            predictions.append(pred_chars)\n",
    "            ground_truths.append(label_chars)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Prediction: {predictions[i]}\")\n",
    "    print(f\"Ground Truth: {ground_truths[i]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
